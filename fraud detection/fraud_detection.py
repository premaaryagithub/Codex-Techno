# -*- coding: utf-8 -*-
"""fraud_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11awTQoQUz7o6lNaJNiTDNtUjY0i11oMK
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

file_path = '/content/drive/My Drive/creditcard.csv'
data= pd.read_csv(file_path)
data.head()

display(data.shape)

display(data.info())

display(data.isnull().sum())

#check class distrubution
data['Class'].value_counts()

"""Feature engineering :  """

from sklearn.preprocessing import StandardScaler

# Scale the 'Amount' and 'Time' features
scaler = StandardScaler()
data['scaled_amount'] = scaler.fit_transform(data['Amount'].values.reshape(-1, 1))
data['scaled_time'] = scaler.fit_transform(data['Time'].values.reshape(-1, 1))

# Drop original time and amount columns
data.drop(['Time', 'Amount'], axis=1, inplace=True)

# Separate features and target
X = data.drop('Class', axis=1)
y = data['Class']

from sklearn.model_selection import train_test_split
# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

"""handling inbalance with SMOTE"""

from imblearn.over_sampling import SMOTE
import numpy as np
# Apply SMOTE to handle class imbalance
sm = SMOTE(random_state=42)
X_train_res, y_train_res = sm.fit_resample(X_train, y_train)

print(f"Before SMOTE: {np.bincount(y_train)}")
print(f"After SMOTE: {np.bincount(y_train_res)}")

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, average_precision_score, auc

#applying ml models for anomaly detection
# Logistic Regression
lr = LogisticRegression(max_iter=1000)
lr.fit(X_train_res, y_train_res)

y_pred_lr = lr.predict(X_test)

# Evaluation
print("Logistic Regression Results:")
print(classification_report(y_test, y_pred_lr))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_lr))

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, lr.predict_proba(X_test)[:, 1])
auprc = auc(recall, precision)
print(f"AUPRC: {auprc:.4f}")

# Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train_res, y_train_res)

y_pred_rf = rf.predict(X_test)

# Evaluation
print("\nRandom Forest Results:")
print(classification_report(y_test, y_pred_rf))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_rf))

# Precision-Recall Curve
precision_rf, recall_rf, _ = precision_recall_curve(y_test, rf.predict_proba(X_test)[:, 1])
auprc_rf = auc(recall_rf, precision_rf)
print(f"AUPRC: {auprc_rf:.4f}")

"""real time  monitoring ðŸ‡°"""

# Function to simulate real-time monitoring
def monitor_transaction(model, transaction):
    proba = model.predict_proba(transaction)[0][1]
    if proba > 0.5:  # Threshold can be adjusted based on business needs
        return f"ALERT: Potential fraud detected (probability: {proba:.2f})"
    else:
        return f"Transaction normal (probability: {proba:.2f})"

# Test with a sample transaction
sample_transaction = X_test.iloc[0:1]
print("\nReal-time Monitoring Simulation:")
print("Logistic Regression:", monitor_transaction(lr, sample_transaction))
print("Random Forest:", monitor_transaction(rf, sample_transaction))

